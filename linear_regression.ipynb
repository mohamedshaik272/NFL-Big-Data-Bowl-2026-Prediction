{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = sorted(glob.glob('data/train/input_*.csv'))\n",
    "output_files = sorted(glob.glob('data/train/output_*.csv'))\n",
    "\n",
    "input_dfs = [pd.read_csv(f) for f in input_files]\n",
    "output_dfs = [pd.read_csv(f) for f in output_files]\n",
    "\n",
    "input_df = pd.concat(input_dfs, ignore_index=True)\n",
    "output_df = pd.concat(output_dfs, ignore_index=True)\n",
    "\n",
    "print(f'Loaded {len(input_files)} weeks')\n",
    "print(f'Input: {input_df.shape}, Output: {output_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse height \"6-1\" -> 73 inches\n",
    "input_df['player_height_inches'] = input_df['player_height'].str.split('-').apply(\n",
    "    lambda x: int(x[0])*12 + int(x[1]) if isinstance(x, list) and len(x)==2 else np.nan\n",
    ")\n",
    "\n",
    "# Calculate age\n",
    "input_df['player_age'] = 2023 - pd.to_datetime(input_df['player_birth_date']).dt.year\n",
    "\n",
    "# Encode categorical variables\n",
    "encoders = {}\n",
    "for col in ['player_position', 'player_side', 'player_role', 'play_direction']:\n",
    "    encoders[col] = LabelEncoder()\n",
    "    input_df[f'{col}_enc'] = encoders[col].fit_transform(input_df[col].fillna('Unknown'))\n",
    "\n",
    "print('Features engineered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = input_df.merge(output_df, on=['game_id', 'play_id', 'nfl_id'], suffixes=('', '_target'))\n",
    "\n",
    "# All 19 features\n",
    "features = [\n",
    "    'x', 'y', 's', 'a', 'dir', 'o',\n",
    "    'ball_land_x', 'ball_land_y',\n",
    "    'absolute_yardline_number',\n",
    "    'player_height_inches', 'player_weight', 'player_age',\n",
    "    'player_position_enc', 'player_side_enc', 'player_role_enc', 'play_direction_enc',\n",
    "    'frame_id', 'num_frames_output',\n",
    "    'player_to_predict'\n",
    "]\n",
    "\n",
    "X = df[features].fillna(0).astype(float)\n",
    "y = df[['x_target', 'y_target']]\n",
    "\n",
    "print(f'Features: {X.shape[1]}')\n",
    "print(f'Samples: {len(X):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Train: {len(X_train):,}, Test: {len(X_test):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "train_time = time.time() - start\n",
    "\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(f'Training time: {train_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "errors = np.sqrt(np.sum((y_test.values - y_test_pred)**2, axis=1))\n",
    "mean_error = errors.mean()\n",
    "\n",
    "print(f'Train RMSE: {train_rmse:.4f}')\n",
    "print(f'Test RMSE:  {test_rmse:.4f}')\n",
    "print(f'Train R²:   {train_r2:.4f}')\n",
    "print(f'Test R²:    {test_r2:.4f}')\n",
    "print(f'Mean Error: {mean_error:.4f} yards')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = (np.abs(model.coef_[0]) + np.abs(model.coef_[1])) / 2\n",
    "feat_imp = pd.DataFrame({'feature': features, 'importance': importance}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feat_imp['feature'], feat_imp['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/linear_regression_feature_importance.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop 10 Features:')\n",
    "print(feat_imp.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].scatter(y_test.iloc[:, 0], y_test_pred[:, 0], alpha=0.3, s=1)\n",
    "axes[0].plot([y_test.iloc[:, 0].min(), y_test.iloc[:, 0].max()], \n",
    "             [y_test.iloc[:, 0].min(), y_test.iloc[:, 0].max()], 'r--')\n",
    "axes[0].set_xlabel('Actual X')\n",
    "axes[0].set_ylabel('Predicted X')\n",
    "axes[0].set_title('X Predictions')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].scatter(y_test.iloc[:, 1], y_test_pred[:, 1], alpha=0.3, s=1)\n",
    "axes[1].plot([y_test.iloc[:, 1].min(), y_test.iloc[:, 1].max()], \n",
    "             [y_test.iloc[:, 1].min(), y_test.iloc[:, 1].max()], 'r--')\n",
    "axes[1].set_xlabel('Actual Y')\n",
    "axes[1].set_ylabel('Predicted Y')\n",
    "axes[1].set_title('Y Predictions')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/linear_regression_predictions.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_x = y_test.iloc[:, 0].values - y_test_pred[:, 0]\n",
    "errors_y = y_test.iloc[:, 1].values - y_test_pred[:, 1]\n",
    "errors_euclidean = np.sqrt(errors_x**2 + errors_y**2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(errors_x, bins=100, alpha=0.7)\n",
    "axes[0].axvline(0, color='r', linestyle='--')\n",
    "axes[0].set_xlabel('Error (yards)')\n",
    "axes[0].set_title(f'X Error (std={np.std(errors_x):.2f})')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].hist(errors_y, bins=100, alpha=0.7)\n",
    "axes[1].axvline(0, color='r', linestyle='--')\n",
    "axes[1].set_xlabel('Error (yards)')\n",
    "axes[1].set_title(f'Y Error (std={np.std(errors_y):.2f})')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "axes[2].hist(errors_euclidean, bins=100, alpha=0.7)\n",
    "axes[2].axvline(mean_error, color='r', linestyle='--', label=f'Mean={mean_error:.2f}')\n",
    "axes[2].set_xlabel('Error (yards)')\n",
    "axes[2].set_title('Euclidean Error')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/linear_regression_error_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'encoders': encoders,\n",
    "    'features': features,\n",
    "    'metrics': {\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'mean_error': mean_error\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('models/linear_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print('Model saved to models/linear_regression_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
