{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('graphs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = sorted(glob.glob('data/train/input_*.csv'))\n",
    "output_files = sorted(glob.glob('data/train/output_*.csv'))\n",
    "\n",
    "input_dfs = [pd.read_csv(f) for f in input_files]\n",
    "output_dfs = [pd.read_csv(f) for f in output_files]\n",
    "\n",
    "input_df = pd.concat(input_dfs, ignore_index=True)\n",
    "output_df = pd.concat(output_dfs, ignore_index=True)\n",
    "\n",
    "print(f'Loaded {len(input_files)} weeks')\n",
    "print(f'Input: {input_df.shape}, Output: {output_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['player_height_inches'] = input_df['player_height'].str.split('-').apply(\n",
    "    lambda x: int(x[0])*12 + int(x[1]) if isinstance(x, list) and len(x)==2 else np.nan\n",
    ")\n",
    "\n",
    "input_df['player_age'] = 2023 - pd.to_datetime(input_df['player_birth_date']).dt.year\n",
    "\n",
    "encoders = {}\n",
    "for col in ['player_position', 'player_side', 'player_role', 'play_direction']:\n",
    "    encoders[col] = LabelEncoder()\n",
    "    input_df[f'{col}_enc'] = encoders[col].fit_transform(input_df[col].fillna('Unknown'))\n",
    "\n",
    "print('Features engineered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = input_df.merge(output_df, on=['game_id', 'play_id', 'nfl_id'], suffixes=('', '_target'))\n\nfeatures = [\n    'x', 'y', 's', 'a', 'dir', 'o',\n    'ball_land_x', 'ball_land_y',\n    'absolute_yardline_number',\n    'player_height_inches', 'player_weight', 'player_age',\n    'player_position_enc', 'player_side_enc', 'player_role_enc', 'play_direction_enc',\n    'frame_id', 'num_frames_output',\n    'player_to_predict'\n]\n\nX = df[features].fillna(0).astype(float)\ny = df[['x_target', 'y_target']]\n\nprint(f'Features: {X.shape[1]}')\nprint(f'Samples: {len(X):,}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled).unsqueeze(2).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled).unsqueeze(2).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).unsqueeze(2).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).to(device)\n",
    "\n",
    "print(f'Train: {len(X_train):,}, Val: {len(X_val):,}, Test: {len(X_test):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size)\n",
    "\n",
    "print(f'Batch size: {batch_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(19, 32, kernel_size=1)\n",
    "        self.lstm = nn.LSTM(32, 64, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(64, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        x = self.fc(h_n[-1])\n",
    "        return x\n",
    "\n",
    "model = CNNLSTM().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "patience = 15\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'models/cnn_lstm.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}')\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping at epoch {epoch+1}')\n",
    "        break\n",
    "\n",
    "train_time = time.time() - start\n",
    "print(f'Training time: {train_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('models/cnn_lstm.pth'))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_train_pred = model(X_train_tensor).cpu().numpy()\n",
    "    y_test_pred = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "print('Predictions generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = np.sqrt(mean_squared_error(y_train.values, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test.values, y_test_pred))\n",
    "train_r2 = r2_score(y_train.values, y_train_pred)\n",
    "test_r2 = r2_score(y_test.values, y_test_pred)\n",
    "\n",
    "errors = np.sqrt(np.sum((y_test.values - y_test_pred)**2, axis=1))\n",
    "mean_error = errors.mean()\n",
    "\n",
    "print(f'Train RMSE: {train_rmse:.4f}')\n",
    "print(f'Test RMSE:  {test_rmse:.4f}')\n",
    "print(f'Train R²:   {train_r2:.4f}')\n",
    "print(f'Test R²:    {test_r2:.4f}')\n",
    "print(f'Mean Error: {mean_error:.4f} yards')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('graphs/cnn_lstm_training_history.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].scatter(y_test.iloc[:, 0], y_test_pred[:, 0], alpha=0.3, s=1)\n",
    "axes[0].plot([y_test.iloc[:, 0].min(), y_test.iloc[:, 0].max()], \n",
    "             [y_test.iloc[:, 0].min(), y_test.iloc[:, 0].max()], 'r--')\n",
    "axes[0].set_xlabel('Actual X')\n",
    "axes[0].set_ylabel('Predicted X')\n",
    "axes[0].set_title('X Predictions')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].scatter(y_test.iloc[:, 1], y_test_pred[:, 1], alpha=0.3, s=1)\n",
    "axes[1].plot([y_test.iloc[:, 1].min(), y_test.iloc[:, 1].max()], \n",
    "             [y_test.iloc[:, 1].min(), y_test.iloc[:, 1].max()], 'r--')\n",
    "axes[1].set_xlabel('Actual Y')\n",
    "axes[1].set_ylabel('Predicted Y')\n",
    "axes[1].set_title('Y Predictions')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/cnn_lstm_predictions.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_x = y_test.iloc[:, 0].values - y_test_pred[:, 0]\n",
    "errors_y = y_test.iloc[:, 1].values - y_test_pred[:, 1]\n",
    "errors_euclidean = np.sqrt(errors_x**2 + errors_y**2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(errors_x, bins=100, alpha=0.7)\n",
    "axes[0].axvline(0, color='r', linestyle='--')\n",
    "axes[0].set_xlabel('Error (yards)')\n",
    "axes[0].set_title(f'X Error (std={np.std(errors_x):.2f})')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].hist(errors_y, bins=100, alpha=0.7)\n",
    "axes[1].axvline(0, color='r', linestyle='--')\n",
    "axes[1].set_xlabel('Error (yards)')\n",
    "axes[1].set_title(f'Y Error (std={np.std(errors_y):.2f})')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "axes[2].hist(errors_euclidean, bins=100, alpha=0.7)\n",
    "axes[2].axvline(mean_error, color='r', linestyle='--', label=f'Mean={mean_error:.2f}')\n",
    "axes[2].set_xlabel('Error (yards)')\n",
    "axes[2].set_title('Euclidean Error')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/cnn_lstm_error_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}